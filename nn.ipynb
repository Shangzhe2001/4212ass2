{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled13.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOA2FPdRYWAsfSWr+UNA1M+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shangzhe2001/4212ass2/blob/main/nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "vTV3x0VK86bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a25d47e-7b8f-4236-9554-829a45cfc606"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  nn on music\n",
        "\n",
        "we use tensorflow to help us build the neural network, the idea is simple\n",
        "\n",
        "as it's a multi-class problem.\n",
        "we build a 3 dense layer with non-linear layer as relu;\n",
        "for the last non-linear  layer to the final output., we use the softmax function.\n",
        "\n",
        "reference : https://www.tensorflow.org/guide/keras/sequential_model?hl=zh-cn\n",
        "\n",
        "\n",
        "for the loss ï¼š\n",
        "\n",
        "for the optimization , we use adam"
      ],
      "metadata": {
        "id": "SOgOJzQK86nv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# deep learning package\n",
        "import tensorflow as tf\n",
        "print(\"TF version:-\", tf.__version__)\n",
        "import keras as k\n",
        "tf.random.set_seed(23)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1rG7KaMHyT3",
        "outputId": "edf793f5-b38c-499f-d63b-e85e3286b88d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF version:- 2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set-Ups\n",
        "import csv\n",
        "import math\n",
        "import random\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import pylab as plt\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/train.csv\", sep=\",\",skipinitialspace = True)\n",
        "#df = pd.read_csv(\"framingham.csv\", sep=\",\")\n",
        "## data split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = df.dropna()\n",
        "df = df.drop(columns=['Track Name'])\n",
        "df[\"Artist Name\"] = df[\"Artist Name\"].astype(str)\n",
        "\n",
        "from sklearn import preprocessing\n",
        "number = preprocessing.LabelEncoder()\n",
        "df[\"Artist Name\"] = number.fit_transform(df[\"Artist Name\"])\n",
        "\n",
        "df_X = df[df.columns[df.columns != 'Class']].copy()\n",
        "df_y = df['Class'].copy()\n",
        "\n",
        "\n",
        "X_train, test_valid_X, y_train, test_valid_y = train_test_split(df_X, df_y, test_size=0.2, random_state=0)\n",
        "print (\"Number of training instances: \", len(X_train), \"\\nNumber of test instances: \", len(test_valid_X)/2)\n",
        "\n",
        "X_dev, X_test, y_dev, y_test = train_test_split(test_valid_X, test_valid_y, train_size=0.5, random_state=0)\n",
        "                                                "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cGmQW8J-XWG",
        "outputId": "afa79f50-2d72-4e15-c8f8-8fa81cca7297"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training instances:  9450 \n",
            "Number of test instances:  1181.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_y.max() # from 0 to 10, totally 11 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGDm-z9zIT8b",
        "outputId": "217caa53-ea0d-405c-fc52-6af64794443d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__DS2N9tJqTV",
        "outputId": "aeff7632-a1fe-4a86-fb35-6ae64f81180b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plotHistory(history):\n",
        "    print(\"Max. Validation Accuracy\",max(history.history[\"val_accuracy\"]))\n",
        "    pd.DataFrame(history.history).plot(figsize=(12,6))\n",
        "    plt.show()\n",
        "\n",
        "def trainModel(model, epochs, optimizer):\n",
        "    \n",
        "    \n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics='accuracy'\n",
        "    )\n",
        "\n",
        "    return model.fit(X_train, y_train, \n",
        "                     \n",
        "                     epochs=epochs, \n",
        "                     batch_size=64, \n",
        "                     validation_data=(X_dev, y_dev)\n",
        "\n",
        "                     )\n",
        "    \n",
        "\n",
        "model_1 = k.models.Sequential([\n",
        "    k.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    k.layers.Dropout(0.4),\n",
        "    \n",
        "    # we add a dropout layer to avoid overfitting\n",
        "    k.layers.Dense(64, activation='relu'),\n",
        "    k.layers.Dropout(0.4),\n",
        "\n",
        "    k.layers.Dense(32, activation='relu'),\n",
        "    k.layers.Dropout(0.4),\n",
        "\n",
        "    k.layers.Dense(11, activation='softmax'),\n",
        "])\n",
        "\n",
        "print(model_1.summary())\n",
        "\n",
        "model_1_history = trainModel(model=model_1, epochs=100, optimizer= opt)\n",
        "\n",
        "# model  evaluation\n",
        "\n",
        "test_loss, test_acc  = model_1.evaluate(X_test, y_test, batch_size=128)\n",
        "print(\"The test Loss is :\",test_loss)\n",
        "print(\"\\nThe Best test Accuracy is :\",test_acc*100)"
      ],
      "metadata": {
        "id": "bAZoXuhm9a8s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a11e1a5-e49c-432c-e750-8cefeb874e50"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_36 (Dense)            (None, 128)               2048      \n",
            "                                                                 \n",
            " dropout_27 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_28 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_29 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 11)                363       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12,747\n",
            "Trainable params: 12,747\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "148/148 [==============================] - 3s 8ms/step - loss: 2321.7544 - accuracy: 0.2747 - val_loss: 2.0890 - val_accuracy: 0.2921\n",
            "Epoch 2/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 15.5195 - accuracy: 0.2851 - val_loss: 2.0956 - val_accuracy: 0.2921\n",
            "Epoch 3/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 2.0896 - accuracy: 0.2849 - val_loss: 2.0992 - val_accuracy: 0.2921\n",
            "Epoch 4/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 2.2448 - accuracy: 0.2849 - val_loss: 2.0973 - val_accuracy: 0.2921\n",
            "Epoch 5/100\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 2.1344 - accuracy: 0.2849 - val_loss: 2.0964 - val_accuracy: 0.2921\n",
            "Epoch 6/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 2.0891 - accuracy: 0.2849 - val_loss: 2.0937 - val_accuracy: 0.2921\n",
            "Epoch 7/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 2.2879 - accuracy: 0.2848 - val_loss: 2.0968 - val_accuracy: 0.2921\n",
            "Epoch 8/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 2.0876 - accuracy: 0.2849 - val_loss: 126.8744 - val_accuracy: 0.2879\n",
            "Epoch 9/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 328.5965 - accuracy: 0.2839 - val_loss: 2.0940 - val_accuracy: 0.2921\n",
            "Epoch 10/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 2.0886 - accuracy: 0.2849 - val_loss: 2.0908 - val_accuracy: 0.2921\n",
            "Epoch 11/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 2.0885 - accuracy: 0.2849 - val_loss: 2.0957 - val_accuracy: 0.2921\n",
            "Epoch 12/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 2.0892 - accuracy: 0.2834 - val_loss: 2.0949 - val_accuracy: 0.2921\n",
            "Epoch 13/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0911 - accuracy: 0.2849 - val_loss: 2.1004 - val_accuracy: 0.2921\n",
            "Epoch 14/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0890 - accuracy: 0.2849 - val_loss: 2.0936 - val_accuracy: 0.2921\n",
            "Epoch 15/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0882 - accuracy: 0.2849 - val_loss: 2.0979 - val_accuracy: 0.2921\n",
            "Epoch 16/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0883 - accuracy: 0.2849 - val_loss: 2.1047 - val_accuracy: 0.2921\n",
            "Epoch 17/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0897 - accuracy: 0.2849 - val_loss: 2.0893 - val_accuracy: 0.2921\n",
            "Epoch 18/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0884 - accuracy: 0.2849 - val_loss: 2.0975 - val_accuracy: 0.2921\n",
            "Epoch 19/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0890 - accuracy: 0.2849 - val_loss: 2.1012 - val_accuracy: 0.2921\n",
            "Epoch 20/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0887 - accuracy: 0.2849 - val_loss: 2.0917 - val_accuracy: 0.2921\n",
            "Epoch 21/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0890 - accuracy: 0.2849 - val_loss: 2.0973 - val_accuracy: 0.2921\n",
            "Epoch 22/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0880 - accuracy: 0.2849 - val_loss: 2.0924 - val_accuracy: 0.2921\n",
            "Epoch 23/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0892 - accuracy: 0.2849 - val_loss: 2.0923 - val_accuracy: 0.2921\n",
            "Epoch 24/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0892 - accuracy: 0.2849 - val_loss: 2.0943 - val_accuracy: 0.2921\n",
            "Epoch 25/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0891 - accuracy: 0.2849 - val_loss: 2.0947 - val_accuracy: 0.2921\n",
            "Epoch 26/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0877 - accuracy: 0.2820 - val_loss: 2.0988 - val_accuracy: 0.2921\n",
            "Epoch 27/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0889 - accuracy: 0.2849 - val_loss: 2.0902 - val_accuracy: 0.2921\n",
            "Epoch 28/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 2.0907 - accuracy: 0.2849 - val_loss: 2.1040 - val_accuracy: 0.2921\n",
            "Epoch 29/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0887 - accuracy: 0.2849 - val_loss: 2.0890 - val_accuracy: 0.2921\n",
            "Epoch 30/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0881 - accuracy: 0.2849 - val_loss: 2.0919 - val_accuracy: 0.2921\n",
            "Epoch 31/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0890 - accuracy: 0.2849 - val_loss: 2.0989 - val_accuracy: 0.2921\n",
            "Epoch 32/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0889 - accuracy: 0.2849 - val_loss: 2.0992 - val_accuracy: 0.2921\n",
            "Epoch 33/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0905 - accuracy: 0.2849 - val_loss: 2.0927 - val_accuracy: 0.2921\n",
            "Epoch 34/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0894 - accuracy: 0.2849 - val_loss: 2.0879 - val_accuracy: 0.2921\n",
            "Epoch 35/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0858 - accuracy: 0.2817 - val_loss: 2.0881 - val_accuracy: 0.2921\n",
            "Epoch 36/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0893 - accuracy: 0.2849 - val_loss: 2.0978 - val_accuracy: 0.2921\n",
            "Epoch 37/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0895 - accuracy: 0.2849 - val_loss: 2.1068 - val_accuracy: 0.2921\n",
            "Epoch 38/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0894 - accuracy: 0.2849 - val_loss: 2.0920 - val_accuracy: 0.2921\n",
            "Epoch 39/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0877 - accuracy: 0.2849 - val_loss: 2.0976 - val_accuracy: 0.2921\n",
            "Epoch 40/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0856 - accuracy: 0.2849 - val_loss: 2.1036 - val_accuracy: 0.2921\n",
            "Epoch 41/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0886 - accuracy: 0.2849 - val_loss: 2.0888 - val_accuracy: 0.2921\n",
            "Epoch 42/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0890 - accuracy: 0.2849 - val_loss: 2.0906 - val_accuracy: 0.2921\n",
            "Epoch 43/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0893 - accuracy: 0.2849 - val_loss: 2.0938 - val_accuracy: 0.2921\n",
            "Epoch 44/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0882 - accuracy: 0.2849 - val_loss: 2.0932 - val_accuracy: 0.2921\n",
            "Epoch 45/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0878 - accuracy: 0.2836 - val_loss: 2.0999 - val_accuracy: 0.2921\n",
            "Epoch 46/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0906 - accuracy: 0.2849 - val_loss: 2.0931 - val_accuracy: 0.2921\n",
            "Epoch 47/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0881 - accuracy: 0.2849 - val_loss: 2.0909 - val_accuracy: 0.2921\n",
            "Epoch 48/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0899 - accuracy: 0.2849 - val_loss: 2.0939 - val_accuracy: 0.2921\n",
            "Epoch 49/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0893 - accuracy: 0.2849 - val_loss: 2.1131 - val_accuracy: 0.1651\n",
            "Epoch 50/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0903 - accuracy: 0.2811 - val_loss: 2.0902 - val_accuracy: 0.2921\n",
            "Epoch 51/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0879 - accuracy: 0.2849 - val_loss: 2.0970 - val_accuracy: 0.2921\n",
            "Epoch 52/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0869 - accuracy: 0.2849 - val_loss: 2.0985 - val_accuracy: 0.2921\n",
            "Epoch 53/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0889 - accuracy: 0.2849 - val_loss: 2.0982 - val_accuracy: 0.2921\n",
            "Epoch 54/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0898 - accuracy: 0.2848 - val_loss: 2.0964 - val_accuracy: 0.2921\n",
            "Epoch 55/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0860 - accuracy: 0.2849 - val_loss: 2.1145 - val_accuracy: 0.2921\n",
            "Epoch 56/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0875 - accuracy: 0.2815 - val_loss: 2.0973 - val_accuracy: 0.2921\n",
            "Epoch 57/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0909 - accuracy: 0.2849 - val_loss: 2.0945 - val_accuracy: 0.2921\n",
            "Epoch 58/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0878 - accuracy: 0.2849 - val_loss: 2.0884 - val_accuracy: 0.2921\n",
            "Epoch 59/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0873 - accuracy: 0.2849 - val_loss: 2.0946 - val_accuracy: 0.2921\n",
            "Epoch 60/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0906 - accuracy: 0.2849 - val_loss: 2.0976 - val_accuracy: 0.2921\n",
            "Epoch 61/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0874 - accuracy: 0.2849 - val_loss: 2.0912 - val_accuracy: 0.2921\n",
            "Epoch 62/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0892 - accuracy: 0.2849 - val_loss: 2.0999 - val_accuracy: 0.2921\n",
            "Epoch 63/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 2.0881 - accuracy: 0.2850 - val_loss: 2.0988 - val_accuracy: 0.2921\n",
            "Epoch 64/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 2.0890 - accuracy: 0.2849 - val_loss: 2.0974 - val_accuracy: 0.2921\n",
            "Epoch 65/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 2.0921 - accuracy: 0.2849 - val_loss: 2.0900 - val_accuracy: 0.2921\n",
            "Epoch 66/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 2.0875 - accuracy: 0.2849 - val_loss: 2.1211 - val_accuracy: 0.2921\n",
            "Epoch 67/100\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 2.0923 - accuracy: 0.2849 - val_loss: 2.0918 - val_accuracy: 0.2921\n",
            "Epoch 68/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 2.0928 - accuracy: 0.2849 - val_loss: 2.0921 - val_accuracy: 0.2921\n",
            "Epoch 69/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0895 - accuracy: 0.2849 - val_loss: 2.0995 - val_accuracy: 0.2921\n",
            "Epoch 70/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0907 - accuracy: 0.2849 - val_loss: 2.0997 - val_accuracy: 0.2921\n",
            "Epoch 71/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0908 - accuracy: 0.2849 - val_loss: 2.0947 - val_accuracy: 0.2921\n",
            "Epoch 72/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0879 - accuracy: 0.2849 - val_loss: 2.0938 - val_accuracy: 0.2921\n",
            "Epoch 73/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0870 - accuracy: 0.2849 - val_loss: 2.0945 - val_accuracy: 0.2921\n",
            "Epoch 74/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0904 - accuracy: 0.2849 - val_loss: 2.0935 - val_accuracy: 0.2921\n",
            "Epoch 75/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0869 - accuracy: 0.2849 - val_loss: 2.0986 - val_accuracy: 0.2921\n",
            "Epoch 76/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0874 - accuracy: 0.2849 - val_loss: 2.0944 - val_accuracy: 0.2921\n",
            "Epoch 77/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0898 - accuracy: 0.2849 - val_loss: 2.0945 - val_accuracy: 0.2921\n",
            "Epoch 78/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0868 - accuracy: 0.2849 - val_loss: 2.1030 - val_accuracy: 0.2921\n",
            "Epoch 79/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0902 - accuracy: 0.2849 - val_loss: 2.0942 - val_accuracy: 0.2921\n",
            "Epoch 80/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0922 - accuracy: 0.2849 - val_loss: 2.1052 - val_accuracy: 0.2921\n",
            "Epoch 81/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0890 - accuracy: 0.2849 - val_loss: 2.0972 - val_accuracy: 0.2921\n",
            "Epoch 82/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0886 - accuracy: 0.2849 - val_loss: 2.0994 - val_accuracy: 0.2921\n",
            "Epoch 83/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0887 - accuracy: 0.2849 - val_loss: 2.0975 - val_accuracy: 0.2921\n",
            "Epoch 84/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 2.0893 - accuracy: 0.2849 - val_loss: 2.0954 - val_accuracy: 0.2921\n",
            "Epoch 85/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 2.0869 - accuracy: 0.2849 - val_loss: 2.0915 - val_accuracy: 0.2921\n",
            "Epoch 86/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 2.0879 - accuracy: 0.2849 - val_loss: 2.0993 - val_accuracy: 0.2921\n",
            "Epoch 87/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 2.0894 - accuracy: 0.2849 - val_loss: 2.1008 - val_accuracy: 0.2921\n",
            "Epoch 88/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 2.0893 - accuracy: 0.2849 - val_loss: 2.1076 - val_accuracy: 0.2921\n",
            "Epoch 89/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 2.0894 - accuracy: 0.2849 - val_loss: 2.0971 - val_accuracy: 0.2921\n",
            "Epoch 90/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 2.0877 - accuracy: 0.2849 - val_loss: 2.0915 - val_accuracy: 0.2921\n",
            "Epoch 91/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 2.0887 - accuracy: 0.2849 - val_loss: 2.0938 - val_accuracy: 0.2921\n",
            "Epoch 92/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 2.0891 - accuracy: 0.2849 - val_loss: 2.0999 - val_accuracy: 0.2921\n",
            "Epoch 93/100\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 2.0895 - accuracy: 0.2849 - val_loss: 2.0974 - val_accuracy: 0.2921\n",
            "Epoch 94/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 2.0895 - accuracy: 0.2849 - val_loss: 2.0879 - val_accuracy: 0.2921\n",
            "Epoch 95/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 2.0879 - accuracy: 0.2849 - val_loss: 2.0946 - val_accuracy: 0.2921\n",
            "Epoch 96/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 2.0908 - accuracy: 0.2849 - val_loss: 2.0857 - val_accuracy: 0.2921\n",
            "Epoch 97/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 2.0901 - accuracy: 0.2849 - val_loss: 2.1039 - val_accuracy: 0.2921\n",
            "Epoch 98/100\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 2.0873 - accuracy: 0.2849 - val_loss: 2.1050 - val_accuracy: 0.2921\n",
            "Epoch 99/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 2.0903 - accuracy: 0.2849 - val_loss: 2.1004 - val_accuracy: 0.2921\n",
            "Epoch 100/100\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 2.0913 - accuracy: 0.2849 - val_loss: 2.0909 - val_accuracy: 0.2921\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 2.0846 - accuracy: 0.2849\n",
            "The test Loss is : 2.084629774093628\n",
            "\n",
            "The Best test Accuracy is : 28.486773371696472\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plotHistory(model_1_history)"
      ],
      "metadata": {
        "id": "uvN9OkRA-U6Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "abaa0a8f-52ed-4489-f3c0-93b7e8ae4aae"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max. Validation Accuracy 0.29212531447410583\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "xg_cl = xgb.XGBClassifier(objective='multi:softmax', n_estimators=2, seed=4212)\n",
        "xg_cl.fit(X_train,y_train)\n",
        "\n",
        "print('GBDT accuracy for training set: %f' % xg_cl.score(X_train, y_train))\n",
        "print('GBDT forest accuracy for test set: %f' % xg_cl.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "4nQVDaHOBgUn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a82db852-3d4f-454f-cb7f-b218c9e5ff46"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GBDT accuracy for training set: 0.469524\n",
            "GBDT forest accuracy for test set: 0.454315\n"
          ]
        }
      ]
    }
  ]
}